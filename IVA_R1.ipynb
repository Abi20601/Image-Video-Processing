{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "mount_file_id": "1kNoE9Wc0mC3zoslWtkozRfMcsRgvSKRT",
      "authorship_tag": "ABX9TyP0t9waoLXiMut8G5Km5xi9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abi20601/Image-Video-Processing/blob/main/IVA_R1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Canny edge detection and Masking**"
      ],
      "metadata": {
        "id": "Xc4N0F99c4pm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQ_1EH-Xjqm8"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "BJo90NqhvVmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = glob.glob('/content/drive/MyDrive/Fish_dataset/*.jpg',recursive=True)"
      ],
      "metadata": {
        "id": "FDuxod2pvrdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orig = np.array([np.asarray(Image.open(img)) for img in paths])\n",
        "plt.figure(figsize=(25,25))\n",
        "\n",
        "for i, img in enumerate(orig[0:5]):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4cy4JQs6zzrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gray = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) for img in orig])\n",
        "plt.figure(figsize=(25,25))\n",
        "\n",
        "for i, img in enumerate(gray[0:5]):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(cv2.cvtColor(img, cv2.COLOR_GRAY2RGB))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OQy38otw0Fks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Thresholding**"
      ],
      "metadata": {
        "id": "lmS4Xj0vox1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The thresholding capacity included here is mean of all the pixels present in the images."
      ],
      "metadata": {
        "id": "7SVPVNmbo-8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thresh = [cv2.threshold(img, np.mean(img), 255, cv2.THRESH_BINARY_INV)[1] for img in gray]\n",
        "thresh[0].shape"
      ],
      "metadata": {
        "id": "Vt9SCwPMFhST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25,25))\n",
        "\n",
        "for i, threshimg in enumerate(thresh[0:5]):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(threshimg,cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aK75FM8KGtYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Edge Detection**"
      ],
      "metadata": {
        "id": "rVX8TAx7pPcV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here edgedetction is done using canny edge detection. And Dilation is used for removing noises from the image."
      ],
      "metadata": {
        "id": "Bg1cABTjpWzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "edges = [cv2.dilate(cv2.Canny(img, 0, 255), None) for img in thresh]"
      ],
      "metadata": {
        "id": "12ka2FZOHULU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25,25))\n",
        "# plt.suptitle(\"Edges\", fontsize=150)\n",
        "\n",
        "for i, edge in enumerate(edges[0:5]):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  # plt.grid(False)\n",
        "  plt.imshow(cv2.cvtColor(edge, cv2.COLOR_GRAY2RGB))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gBRQ-ZRMHdxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Masking**"
      ],
      "metadata": {
        "id": "orcgNLFQqiIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Masking is done for creating a mask by finding the contour regions of the binary image.After finding the contours in the input image, we will find the largest contour which will be the object of interest."
      ],
      "metadata": {
        "id": "LEZv7tvvqtXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "masked = []\n",
        "segmented = []\n",
        "for i, img in enumerate(edges):\n",
        "  cnt = sorted(cv2.findContours(img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)[-2], key=cv2.contourArea)[-1]\n",
        "  mask = np.zeros((256,256), np.uint8)\n",
        "  masked.append(cv2.drawContours(mask, [cnt],-1, 255, -1))"
      ],
      "metadata": {
        "id": "rQhfdKrQHlWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25,25))\n",
        "\n",
        "for i, maskimg in enumerate(masked[0:5]):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(maskimg, cmap='gray')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nKxY-TIXIJqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.feature import canny\n",
        "from scipy import ndimage as ndi\n",
        "\n",
        "plt.figure(figsize=(25,5))\n",
        "path = \"/content/drive/MyDrive/Fish_dataset/\"\n",
        "\n",
        "for file_name in os.listdir(path):\n",
        "    if file_name.endswith(\".jpg\"):\n",
        "        image = cv2.imread(os.path.join(path, file_name))\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply Canny edge detection algorithm\n",
        "        edges = canny(gray / 255.)\n",
        "\n",
        "        # Plot the Canny edge detection output\n",
        "        fig, ax = plt.subplots(figsize=(4, 3))\n",
        "        ax.imshow(edges, cmap=plt.cm.gray, interpolation='nearest')\n",
        "        ax.axis('off')\n",
        "        ax.set_title('Canny detector')\n",
        "\n",
        "        # Fill the holes in the Canny output\n",
        "        fill_coins = ndi.binary_fill_holes(edges)\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(4, 3))\n",
        "        ax.imshow(fill_coins, cmap=plt.cm.gray, interpolation='nearest')\n",
        "        ax.axis('off')\n",
        "        ax.set_title('Filling the holes')"
      ],
      "metadata": {
        "id": "bTDaRB4dUrIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Segmentation"
      ],
      "metadata": {
        "id": "DOttLWj3uyeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is done by taking a bitwise_and of both masked image and original image.The the final segmented image is converted back to colour image."
      ],
      "metadata": {
        "id": "NcfPgC9Hu3xA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i,mas in enumerate(edges(0:5)):\n",
        "  dst = cv2.bitwise_and(orig[i], orig[i], mask=mas)\n",
        "  segmented.append(cv2.cvtColor(dst, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "2miaYbhzIRBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25,25))\n",
        "\n",
        "for i, segimg in enumerate(segmented[0:5]):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(cv2.cvtColor(segimg, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x4loUVELIm9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Otsu's Method**"
      ],
      "metadata": {
        "id": "HIYfaQhfvVTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(25,5))\n",
        "for i in range(1, 6):\n",
        "    # Read image and convert to RGB format\n",
        "    img = cv2.imread(f\"/content/drive/MyDrive/Fish_dataset/0{i}.jpg\")\n",
        "    b, g, r = cv2.split(img)\n",
        "    rgb_img = cv2.merge([r, g, b])\n",
        "\n",
        "    # Convert image to grayscale and apply Otsu's thresholding\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
        "\n",
        "    # Apply morphological closing to remove noise and fill gaps\n",
        "    kernel = np.ones((2, 2), np.uint8)\n",
        "    closing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
        "\n",
        "    # Apply distance transform to find sure foreground and unknown regions\n",
        "    sure_bg = cv2.dilate(closing, kernel, iterations=3)\n",
        "    dist_transform = cv2.distanceTransform(sure_bg, cv2.DIST_L2, 3)\n",
        "    ret, sure_fg = cv2.threshold(dist_transform, 0.1*dist_transform.max(), 255, 0)\n",
        "    sure_fg = np.uint8(sure_fg)\n",
        "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
        "\n",
        "    # Apply watershed segmentation\n",
        "    ret, markers = cv2.connectedComponents(sure_fg)\n",
        "    markers = markers + 1\n",
        "    markers[unknown == 255] = 0\n",
        "    markers = cv2.watershed(img, markers)\n",
        "    img[markers == -1] = [255, 0, 0]\n",
        "\n",
        "\n",
        "    # Display input image and thresholded image\n",
        "    plt.subplot(2, 5, i), plt.imshow(rgb_img)\n",
        "    plt.title(f\"Image{i}\"), plt.xticks([]), plt.yticks([])\n",
        "    plt.subplot(2, 5, i+5), plt.imshow(thresh, 'gray')\n",
        "    plt.title(f\"Otsu's{i}\"), plt.xticks([]), plt.yticks([])"
      ],
      "metadata": {
        "id": "Ts9yA2FVREsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CHROMATICITY SEGMENTATION**"
      ],
      "metadata": {
        "id": "xxRc_CmOdw8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Gaussian Distribution\n",
        "def gaussian(p,mean,std):\n",
        "    return np.exp(-(p-mean)**2/(2*std**2))*(1/(std*((2*np.pi)**0.5)))"
      ],
      "metadata": {
        "id": "kqp1O7eg0tIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from skimage.filters import threshold_multiotsu\n",
        "for i in range(5):\n",
        "  patch = orig[i][250:300,300:350,:]\n",
        "\n",
        "  patch_R = patch[:,:,0]*1.0/patch.sum(axis=2)\n",
        "  patch_G = patch[:,:,1]*1.0/patch.sum(axis=2)\n",
        "  # For the R axis\n",
        "  std_patch_R = np.std(patch_R.flatten())\n",
        "  mean_patch_R = np.mean(patch_R.flatten())\n",
        "  # For the G axis\n",
        "  std_patch_G = np.std(patch_G.flatten())\n",
        "  mean_patch_G = np.mean(patch_G.flatten())\n",
        "\n",
        "  prob_R = gaussian(patch_R,mean_patch_R,std_patch_R)\n",
        "  prob_G = gaussian(patch_G,mean_patch_G,std_patch_G)\n",
        "  prob=prob_R * prob_G\n",
        "\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(prob)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5Dwq6nvIxHxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uCc7eWMX1dfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shape Analysis"
      ],
      "metadata": {
        "id": "u5ZkVjsoQZBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fourier Transformation and Reconstruction**"
      ],
      "metadata": {
        "id": "9hUFn1afRUTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import fftpack\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import PIL.Image as Image\n",
        "\n",
        "# Load the shape as a binary image\n",
        "shape = np.array(Image.open('/content/drive/MyDrive/Fish_dataset/03.jpg').convert('L')) > 128\n",
        "\n",
        "\n",
        "image = Image.open('/content/drive/MyDrive/Fish_dataset/03.jpg')\n",
        "print(f'Bit Depth: {image.mode}')\n",
        "print(f'Color Mode: {image.info.get(\"color_mode\")}')\n",
        "\n",
        "# Compute the contour of the shape\n",
        "contour = np.zeros_like(shape, dtype=np.uint8)\n",
        "contours, _ = cv2.findContours(shape.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "cv2.drawContours(contour, contours, 0, 255, thickness=1)\n",
        "\n",
        "# # Compute the Fourier descriptors of the shape\n",
        "fourier_coeffs = fftpack.fft(contour.flatten())\n",
        "descriptor = np.abs(fourier_coeffs[:len(fourier_coeffs)//2])\n",
        "\n",
        "# # Reconstruct the contour from the Fourier descriptors\n",
        "reconstructed_coeffs = np.zeros_like(fourier_coeffs)\n",
        "reconstructed_coeffs[:len(descriptor)] = descriptor\n",
        "reconstructed_coeffs[-len(descriptor):] = descriptor[::-1]\n",
        "reconstructed_contour = fftpack.ifft(reconstructed_coeffs).real.reshape(contour.shape)\n",
        "\n",
        "\n",
        "# Normalize the reconstructed contour to have the same range of pixel values as the original shape\n",
        "reconstructed_contour = (reconstructed_contour - reconstructed_contour.min()) / (reconstructed_contour.max() - reconstructed_contour.min()) * 255\n",
        "\n",
        "# Plot the original shape and the reconstructed shape\n",
        "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
        "ax[0].imshow(shape, cmap='gray')\n",
        "ax[0].set_title('Original Shape')\n",
        "ax[1].imshow(reconstructed_contour, cmap='gray')\n",
        "ax[1].set_title('Reconstructed Shape')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cpBTZ3Ug6bpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "img = plt.imread(\"/content/drive/MyDrive/Fish_dataset/04.jpg\")\n",
        "img = cv2.bitwise_not(img)\n",
        "grayImage = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "ret, img_bin = cv2.threshold(grayImage, 127, 255, cv2.THRESH_BINARY)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(img_bin,cmap=\"gray\")\n",
        "\n",
        "for i, row in enumerate(img_bin):\n",
        "    for j, value in enumerate(row):\n",
        "        if value == 255:\n",
        "            start_point = [i, j]\n",
        "            print(start_point, value)\n",
        "            break\n",
        "    else:\n",
        "        continue\n",
        "    break\n",
        "\n",
        "b = np.array([start_point],dtype=int)\n",
        "c = np.array([[start_point[0],start_point[1]-1]],dtype=int)\n",
        "\n",
        "#Different Sequence for different position of c\n",
        "seq = [[0,7,6,5,4,3,2,1],\n",
        "        [1,0,7,6,5,4,3,2],\n",
        "        [2,1,0,7,6,5,4,3],\n",
        "        [3,2,1,0,7,6,5,4],\n",
        "        [4,3,2,1,0,7,6,5],\n",
        "        [5,4,3,2,1,0,7,6],\n",
        "        [6,5,4,3,2,1,0,7],\n",
        "        [7,6,5,4,3,2,1,0]]\n",
        "\n",
        "while True:\n",
        "    latest_b = b[len(b)-1]\n",
        "    latest_c = c[len(c)-1]\n",
        "    diff = b[len(b)-1] - c[len(c)-1]\n",
        "    if (diff == [0,-1]).all():\n",
        "        seq_no = 0\n",
        "    if (diff == [1,-1]).all():\n",
        "        seq_no = 1\n",
        "    if (diff == [1,0]).all():\n",
        "        seq_no = 2\n",
        "    if (diff == [1,1]).all():\n",
        "        seq_no = 3\n",
        "    if (diff == [0,1]).all():\n",
        "        seq_no = 4\n",
        "    if (diff == [-1,1]).all():\n",
        "        seq_no = 5\n",
        "    if (diff == [-1,0]).all():\n",
        "        seq_no = 6\n",
        "    if (diff == [-1,-1]).all():\n",
        "        seq_no = 7\n",
        "\n",
        "    for i in seq[seq_no]:\n",
        "        if i==0 and (latest_b[1]+1<img_bin.shape[1]) and (img_bin[latest_b[0]][latest_b[1]+1] == 255):\n",
        "            new_b = [latest_b[0], latest_b[1]+1]\n",
        "            new_c = [latest_b[0]-1,latest_b[1]+1]\n",
        "            break\n",
        "\n",
        "        if i==1 and (latest_b[0]-1>=0)and(latest_b[1]+1<img_bin.shape[1]) and (img_bin[latest_b[0]-1][latest_b[1]+1] == 255):\n",
        "            new_b = [latest_b[0]-1, latest_b[1]+1]\n",
        "            new_c = [latest_b[0]-1,latest_b[1]]\n",
        "            break\n",
        "\n",
        "        if i==2 and (latest_b[0]-1>=0) and (img_bin[latest_b[0]-1][latest_b[1]] == 255):\n",
        "            new_b = [latest_b[0]-1, latest_b[1]]\n",
        "            new_c = [latest_b[0]-1, latest_b[1]-1]\n",
        "            break\n",
        "\n",
        "        if i==3 and (latest_b[0]-1>=0)and(latest_b[1]-1>=0) and (img_bin[latest_b[0]-1][latest_b[1]-1] == 255):\n",
        "            new_b = [latest_b[0]-1, latest_b[1]-1]\n",
        "            new_c = [latest_b[0], latest_b[1]-1]\n",
        "            break\n",
        "\n",
        "\n",
        "        if i==4 and (latest_b[1]-1>=0) and (img_bin[latest_b[0]][latest_b[1]-1] == 255):\n",
        "            new_b = [latest_b[0], latest_b[1]-1]\n",
        "            new_c = [latest_b[0]+1, latest_b[1]-1]\n",
        "            break\n",
        "\n",
        "        if i==5 and (latest_b[0]+1<img_bin.shape[0])and(latest_b[1]-1>=0) and (img_bin[latest_b[0]+1][latest_b[1]-1] == 255):\n",
        "            new_b = [latest_b[0]+1, latest_b[1]-1]\n",
        "            new_c = [latest_b[0]+1, latest_b[1]]\n",
        "            break\n",
        "\n",
        "        if i==6 and (latest_b[0]+1<img_bin.shape[0]) and (img_bin[latest_b[0]+1][latest_b[1]] == 255):\n",
        "            new_b = [latest_b[0]+1, latest_b[1]]\n",
        "            new_c = [latest_b[0]+1, latest_b[1]+1]\n",
        "            break\n",
        "\n",
        "        if i==7 and (latest_b[0]+1<img_bin.shape[0])and(latest_b[1]+1<img_bin.shape[1]) and (img_bin[latest_b[0]+1][latest_b[1]+1] == 255):\n",
        "            new_b = [latest_b[0]+1, latest_b[1]+1]\n",
        "            new_c = [latest_b[0], latest_b[1]+1]\n",
        "            break\n",
        "\n",
        "\n",
        "    b = np.append(b,[new_b],axis=0)\n",
        "    c = np.append(c,[new_c],axis=0)\n",
        "    if (b[0] == b[len(b)-1]).all():\n",
        "        break"
      ],
      "metadata": {
        "id": "3JKjZ1LOtNuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boundary = np.zeros((img_bin.shape[0],img_bin.shape[1]),dtype=int)\n",
        "for i in range(0, b.shape[0]):\n",
        "    boundary[b[i][0], b[i][1]] = 255\n",
        "\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.imshow(boundary,cmap=\"gray\")"
      ],
      "metadata": {
        "id": "PvG8ZTxlt-D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bzk3Nuc1usyM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}